{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d51b54-b66c-4b27-8f52-6ded3de01b29",
   "metadata": {},
   "source": [
    "# Kaggle Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d868e8ca-f1af-4f15-9580-c222aceb087f",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14a350f3-b564-4482-83fe-c1f498bcf565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "import ast\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1851488-ac80-4afb-999f-5e96a8f7e17e",
   "metadata": {},
   "source": [
    "## Set Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d75c673-e59a-4551-a79c-5ddc5cfece6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(RANDOM_SEED):\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "seed = 1\n",
    "set_all_seeds(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f56404f-f883-4f2b-bb31-02915475343e",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e88ecc4-2712-4ce4-8f84-cf7e7a977055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# comcat train and test data for data process\n",
    "test_data['price'] = -1\n",
    "train_data = pd.concat([train_data, test_data], axis=0)\n",
    "\n",
    "# initial removal of unwanted features\n",
    "drop_columns = ['id','scrape_id','last_scraped','picture_url','host_id','host_name','name']\n",
    "train_data = train_data.drop(drop_columns, axis=1)\n",
    "\n",
    "# avoid err in xgboost\n",
    "train_data['host_verifications'] = train_data['host_verifications'].str.replace('[', '(')\n",
    "train_data['host_verifications'] = train_data['host_verifications'].str.replace(']', ')')\n",
    "\n",
    "# deal with incomplete data\n",
    "categorical_columns_with_nans = ['host_is_superhost', 'bathrooms_text']\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "train_data[categorical_columns_with_nans] = imputer.fit_transform(train_data[categorical_columns_with_nans])\n",
    "\n",
    "beds_imputer = SimpleImputer(strategy='median')\n",
    "train_data['beds'] = beds_imputer.fit_transform(train_data[['beds']])\n",
    "\n",
    "train_data['description'] = train_data['description'].fillna('')\n",
    "\n",
    "# add feature description_length\n",
    "train_data['description_length'] = train_data['description'].apply(len)\n",
    "train_data = train_data.drop('description', axis=1)\n",
    "\n",
    "# onehot encode\n",
    "categorical_columns = train_data.select_dtypes(include=['object']).columns\n",
    "categorical_columns_to_encode = [col for col in categorical_columns if len(train_data[col].unique()) <= 20]\n",
    "train_data = pd.get_dummies(train_data, columns=categorical_columns_to_encode, drop_first=True)\n",
    "\n",
    "# add feature amenities_count\n",
    "train_data['amenities_count'] = train_data['amenities'].apply(lambda x: len(x.split(',')))\n",
    "\n",
    "# only keep year info of host_since\n",
    "train_data['host_since'] = pd.to_datetime(train_data['host_since'])\n",
    "train_data['host_since'] = train_data['host_since'].dt.year + train_data['host_since'].dt.month / 12\n",
    "train_data['host_since'] = train_data['host_since'].astype('float64')\n",
    "\n",
    "# extract numbers from bathrooms_text\n",
    "train_data['bathrooms_text'] = train_data['bathrooms_text'].replace(to_replace='half', value='0.5', regex=True)\n",
    "train_data['bathrooms_text'] = train_data['bathrooms_text'].replace(to_replace='Half', value='0.5', regex=True)\n",
    "train_data['bathrooms_text'] = train_data['bathrooms_text'].str.extract('(\\d+\\.?\\d*)').astype('float64')\n",
    "train_data['bathrooms_text'] = train_data['bathrooms_text'].fillna(train_data['bathrooms_text'].mean())\n",
    "\n",
    "x = train_data.drop(['price','property_type','neighbourhood_cleansed', 'amenities'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "gmm = GaussianMixture(n_components=6, covariance_type='full', init_params='kmeans', random_state=seed).fit(x)\n",
    "train_data['gmm_cluster'] = gmm.predict(x)\n",
    "\n",
    "train_data = pd.get_dummies(train_data, columns=['property_type','neighbourhood_cleansed'], drop_first=True)\n",
    "\n",
    "# advance drop cols\n",
    "train_data = train_data.drop(['minimum_nights','maximum_nights','minimum_minimum_nights','maximum_minimum_nights',\n",
    "                              'minimum_maximum_nights','maximum_maximum_nights','availability_60','availability_90',\n",
    "                              'number_of_reviews_ltm','number_of_reviews_l30d'], axis=1)\n",
    "\n",
    "# split test and train data\n",
    "test_data = train_data[train_data['price'] == -1].drop(columns=['price'])\n",
    "train_data = train_data[train_data['price'] != -1]\n",
    "\n",
    "# deal with amenities\n",
    "amenities_cols = ['Lock on bedroom door', 'Indoor fireplace', 'Dishwasher', 'BBQ grill', 'Barbecue utensils', 'Fire pit',\n",
    "                  'Outdoor dining area', 'Sun loungers', 'Outdoor furniture', 'Private patio or balcony', 'Private backyard â€“ Fully fenced', 'Pool']\n",
    "\n",
    "for i in amenities_cols: \n",
    "    train_data[i] = 0\n",
    "for i in train_data.index:\n",
    "    for item in amenities_cols:\n",
    "        if item in ast.literal_eval(train_data.loc[i, 'amenities']):\n",
    "            train_data.loc[i, item] = 1\n",
    "train_data = train_data.drop(['amenities'], axis=1)\n",
    "\n",
    "for i in amenities_cols: \n",
    "    test_data[i] = 0\n",
    "for i in test_data.index:\n",
    "    for item in amenities_cols:\n",
    "        if item in ast.literal_eval(test_data.loc[i, 'amenities']):\n",
    "            test_data.loc[i, item] = 1\n",
    "test_data = test_data.drop(['amenities'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba602c01-0be1-405f-8338-90dd6341f940",
   "metadata": {},
   "source": [
    "## Tuning RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1eba78-b07d-4213-8dca-7b422cdee82d",
   "metadata": {},
   "source": [
    "### Tune n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae863424-1bbd-42d0-a1fb-54704fa44dbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best score across for RF:\n",
      " 0.5532931897551331\n",
      "Best parameters for RF:\n",
      " {'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data.drop(\"price\", axis=1)\n",
    "y_train = train_data['price'].astype('int64')\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=seed)\n",
    "grid = GridSearchCV(estimator=rf, param_grid=params, cv=5, n_jobs=-1, scoring='f1_macro', verbose=10)\n",
    "grid.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best score across for RF:\\n\", grid.best_score_)\n",
    "print(\"Best parameters for RF:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b40ca0-b811-4505-a1d8-9d43a4e07c26",
   "metadata": {},
   "source": [
    "### Tune max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fd6e006-6546-498a-bde2-be182087b4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best score across for RF:\n",
      " 0.5532931897551331\n",
      "Best parameters for RF:\n",
      " {'max_depth': None, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data.drop(\"price\", axis=1)\n",
    "y_train = train_data['price'].astype('int64')\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [900],\n",
    "    'max_depth': [5, 10, 15, 20, 25, 30, None]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=seed)\n",
    "grid = GridSearchCV(estimator=rf, param_grid=params, cv=5, n_jobs=-1, scoring='f1_macro', verbose=10)\n",
    "grid.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best score across for RF:\\n\", grid.best_score_)\n",
    "print(\"Best parameters for RF:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a27b18-0327-49a5-a810-75eebf305de2",
   "metadata": {},
   "source": [
    "### Tune min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fd0ba1e-6dbe-4b4a-a11e-db7cecbd8878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best score across for RF:\n",
      " 0.5532931897551331\n",
      "Best parameters for RF:\n",
      " {'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data.drop(\"price\", axis=1)\n",
    "y_train = train_data['price'].astype('int64')\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [900],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=seed)\n",
    "grid = GridSearchCV(estimator=rf, param_grid=params, cv=5, n_jobs=-1, scoring='f1_macro', verbose=10)\n",
    "grid.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best score across for RF:\\n\", grid.best_score_)\n",
    "print(\"Best parameters for RF:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d653ad-c495-41a9-b6a5-23c3c3a7d80d",
   "metadata": {},
   "source": [
    "### Tune min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1108c526-a2d1-47bf-b339-007fce83bc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best score across for RF:\n",
      " 0.5532931897551331\n",
      "Best parameters for RF:\n",
      " {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data.drop(\"price\", axis=1)\n",
    "y_train = train_data['price'].astype('int64')\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [900],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_leaf': [1],\n",
    "    'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=seed)\n",
    "grid = GridSearchCV(estimator=rf, param_grid=params, cv=5, n_jobs=-1, scoring='f1_macro', verbose=10)\n",
    "grid.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best score across for RF:\\n\", grid.best_score_)\n",
    "print(\"Best parameters for RF:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f165e291-f8e9-44f2-822a-ed40d0364a71",
   "metadata": {},
   "source": [
    "### Tune class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d87eb687-134a-4835-87ec-1f7f7ea8a402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best score across for RF:\n",
      " 0.5539357240702674\n",
      "Best parameters for RF:\n",
      " {'class_weight': 'balanced_subsample', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data.drop(\"price\", axis=1)\n",
    "y_train = train_data['price'].astype('int64')\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [900],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_leaf': [1],\n",
    "    'min_samples_split': [2],\n",
    "    'class_weight': ['balanced', 'balanced_subsample', None]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=seed)\n",
    "grid = GridSearchCV(estimator=rf, param_grid=params, cv=5, n_jobs=-1, scoring='f1_macro', verbose=10)\n",
    "grid.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best score across for RF:\\n\", grid.best_score_)\n",
    "print(\"Best parameters for RF:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7c3272-0754-4f13-b64a-9cb40b4c4199",
   "metadata": {},
   "source": [
    "## Tuning Xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d562368d-8739-4ac4-9768-0e4f0eef0e6e",
   "metadata": {},
   "source": [
    "### Tune max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90b7b2e-bb24-4ee4-a740-72192dc8de54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best score across for Xgboost:\n",
      " 0.5614793442431969\n",
      "Best parameters for Xgboost:\n",
      " {'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data.drop(\"price\", axis=1)\n",
    "y_train = train_data['price'].astype('int64')\n",
    "\n",
    "params = {\n",
    "    'max_depth': [10, 20, None]\n",
    "}\n",
    "\n",
    "xgboost = XGBClassifier(n_jobs=-1, random_state=seed)\n",
    "grid = GridSearchCV(estimator=xgboost, param_grid=params, cv=5, n_jobs=-1, scoring='f1_macro', verbose=10)\n",
    "grid.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best score across for Xgboost:\\n\", grid.best_score_)\n",
    "print(\"Best parameters for Xgboost:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d7587f-276b-4a3c-9ac0-1d6df1ea2897",
   "metadata": {},
   "source": [
    "### Tune n_estimators and learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a937943-a1ef-4697-b59f-7234cd3d0fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best score across for Xgboost:\n",
      " 0.5682965977278766\n",
      "Best parameters for Xgboost:\n",
      " {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 800}\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data.drop(\"price\", axis=1)\n",
    "y_train = train_data['price'].astype('int64')\n",
    "\n",
    "params = {\n",
    "    'max_depth': [10],\n",
    "    'n_estimators': [300, 500, 800],\n",
    "    'learning_rate': [0.05, 0.3, 1]\n",
    "}\n",
    "\n",
    "xgboost = XGBClassifier(n_jobs=-1, random_state=seed)\n",
    "grid = GridSearchCV(estimator=xgboost, param_grid=params, cv=5, n_jobs=-1, scoring='f1_macro', verbose=10)\n",
    "grid.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best score across for Xgboost:\\n\", grid.best_score_)\n",
    "print(\"Best parameters for Xgboost:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbaa6fe-b866-4f2e-83e6-95a8ed17c5bb",
   "metadata": {},
   "source": [
    "### Tune min_child_weight and subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5a45bf5-7664-4d17-a2d7-cb93ebc4535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Best score across for Xgboost:\n",
      " 0.5696654052539721\n",
      "Best parameters for Xgboost:\n",
      " {'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 0.4, 'n_estimators': 800, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data.drop(\"price\", axis=1)\n",
    "y_train = train_data['price'].astype('int64')\n",
    "\n",
    "params = {\n",
    "    'max_depth': [10],\n",
    "    'n_estimators': [800],\n",
    "    'learning_rate': [0.05],\n",
    "    'min_child_weight': [0.4, 0.6, 1],\n",
    "    'subsample': [0.2, 0.4, 0.6, 0.8, 1]\n",
    "}\n",
    "\n",
    "xgboost = XGBClassifier(n_jobs=-1, random_state=seed)\n",
    "grid = GridSearchCV(estimator=xgboost, param_grid=params, cv=5, n_jobs=-1, scoring='f1_macro', verbose=10)\n",
    "grid.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best score across for Xgboost:\\n\", grid.best_score_)\n",
    "print(\"Best parameters for Xgboost:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7910d87-9705-4635-a35e-46c99b4c424f",
   "metadata": {},
   "source": [
    "### Tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa9ada4-c9d8-4950-a2b2-712c5cbd29de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best score across for Xgboost:\n",
      " 0.5699934924611786\n",
      "Best parameters for Xgboost:\n",
      " {'gamma': 0.2, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 0.4, 'n_estimators': 800, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data.drop(\"price\", axis=1)\n",
    "y_train = train_data['price'].astype('int64')\n",
    "\n",
    "params = {\n",
    "    'max_depth': [10],\n",
    "    'n_estimators': [800],\n",
    "    'learning_rate': [0.05],\n",
    "    'min_child_weight': [0.4],\n",
    "    'subsample': [0.6],\n",
    "    'gamma': [0, 0.2, 0.4, 0.6, 0.8]\n",
    "}\n",
    "\n",
    "xgboost = XGBClassifier(n_jobs=-1, random_state=seed)\n",
    "grid = GridSearchCV(estimator=xgboost, param_grid=params, cv=5, n_jobs=-1, scoring='f1_macro', verbose=10)\n",
    "grid.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best score across for Xgboost:\\n\", grid.best_score_)\n",
    "print(\"Best parameters for Xgboost:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454993b5-7692-4a45-b475-c046c02c909e",
   "metadata": {},
   "source": [
    "### Tune colsample_bylevel and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b6e44c9-628f-474e-b37b-f811fb221a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best score across for Xgboost:\n",
      " 0.5715224601130611\n",
      "Best parameters for Xgboost:\n",
      " {'colsample_bylevel': 0.8, 'colsample_bytree': 0.6, 'gamma': 0.2, 'learning_rate': 0.05, 'max_depth': 10, 'min_child_weight': 0.4, 'n_estimators': 800, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data.drop(\"price\", axis=1)\n",
    "y_train = train_data['price'].astype('int64')\n",
    "\n",
    "params = {\n",
    "    'max_depth': [10],\n",
    "    'n_estimators': [800],\n",
    "    'learning_rate': [0.05],\n",
    "    'min_child_weight': [0.4],\n",
    "    'subsample': [0.6],\n",
    "    'gamma': [0.2],\n",
    "    'colsample_bylevel': [0.4, 0.6, 0.8],\n",
    "    'colsample_bytree': [0.4, 0.6, 0.8]\n",
    "}\n",
    "\n",
    "xgboost = XGBClassifier(n_jobs=-1, random_state=seed)\n",
    "grid = GridSearchCV(estimator=xgboost, param_grid=params, cv=5, n_jobs=-1, scoring='f1_macro', verbose=10)\n",
    "grid.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best score across for Xgboost:\\n\", grid.best_score_)\n",
    "print(\"Best parameters for Xgboost:\\n\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68242d26-e1d6-45a7-93e4-da2be7b7cf72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
