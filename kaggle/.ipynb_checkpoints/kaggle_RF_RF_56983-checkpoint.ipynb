{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d51b54-b66c-4b27-8f52-6ded3de01b29",
   "metadata": {},
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d868e8ca-f1af-4f15-9580-c222aceb087f",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a350f3-b564-4482-83fe-c1f498bcf565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from category_encoders import BinaryEncoder\n",
    "import ast\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.utils import resample\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1851488-ac80-4afb-999f-5e96a8f7e17e",
   "metadata": {},
   "source": [
    "## Set Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d75c673-e59a-4551-a79c-5ddc5cfece6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(RANDOM_SEED):\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_all_seeds(666)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f56404f-f883-4f2b-bb31-02915475343e",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e88ecc4-2712-4ce4-8f84-cf7e7a977055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# comcat train and test data for data process\n",
    "test_data['price'] = -1\n",
    "train_data = pd.concat([train_data, test_data], axis=0)\n",
    "\n",
    "# initial removal of unwanted features\n",
    "drop_columns = ['id','scrape_id','last_scraped','picture_url','host_id','host_name','name']\n",
    "train_data = train_data.drop(drop_columns, axis=1)\n",
    "\n",
    "# deal with incomplete data\n",
    "categorical_columns_with_nans = ['host_is_superhost', 'bathrooms_text']\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "train_data[categorical_columns_with_nans] = imputer.fit_transform(train_data[categorical_columns_with_nans])\n",
    "\n",
    "beds_imputer = SimpleImputer(strategy='median')\n",
    "train_data['beds'] = beds_imputer.fit_transform(train_data[['beds']])\n",
    "\n",
    "train_data['description'] = train_data['description'].fillna('')\n",
    "\n",
    "# add feature description_length\n",
    "train_data['description_length'] = train_data['description'].apply(len)\n",
    "train_data = train_data.drop('description', axis=1)\n",
    "\n",
    "# # label encode\n",
    "# label_encoder = LabelEncoder()\n",
    "# train_data['host_is_superhost'] = label_encoder.fit_transform(train_data['host_is_superhost'])\n",
    "# train_data['host_has_profile_pic'] = label_encoder.fit_transform(train_data['host_has_profile_pic'])\n",
    "# train_data['host_identity_verified'] = label_encoder.fit_transform(train_data['host_identity_verified'])\n",
    "# train_data['has_availability'] = label_encoder.fit_transform(train_data['has_availability'])\n",
    "# train_data['instant_bookable'] = label_encoder.fit_transform(train_data['instant_bookable'])\n",
    "\n",
    "# onehot encode\n",
    "categorical_columns = train_data.select_dtypes(include=['object']).columns\n",
    "categorical_columns_to_encode = [col for col in categorical_columns if len(train_data[col].unique()) <= 20]\n",
    "train_data = pd.get_dummies(train_data, columns=categorical_columns_to_encode, drop_first=True)\n",
    "\n",
    "# add feature amenities_count\n",
    "train_data['amenities_count'] = train_data['amenities'].apply(lambda x: len(x.split(',')))\n",
    "train_data = train_data.drop('amenities', axis=1)\n",
    "\n",
    "train_data = pd.get_dummies(train_data, columns=['property_type','neighbourhood_cleansed'], drop_first=True)\n",
    "\n",
    "# only keep year info of host_since\n",
    "train_data['host_since'] = pd.to_datetime(train_data['host_since'])\n",
    "train_data['host_since'] = train_data['host_since'].dt.year + train_data['host_since'].dt.month / 12\n",
    "train_data['host_since'] = train_data['host_since'].astype('float64')\n",
    "\n",
    "# extract numbers from bathrooms_text\n",
    "# train_data['bathrooms_shared'] = train_data['bathrooms_text'].isin(['shared', 'Shared'])\n",
    "# train_data['bathrooms_private'] = train_data['bathrooms_text'].isin(['private', 'Private'])\n",
    "# train_data['bathrooms_text'] = train_data['bathrooms_text'].replace(to_replace='half', value='0.5', regex=True)\n",
    "# train_data['bathrooms_text'] = train_data['bathrooms_text'].replace(to_replace='Half', value='0.5', regex=True)\n",
    "train_data['bathrooms_text'] = train_data['bathrooms_text'].str.extract('(\\d+\\.?\\d*)').astype('float64')\n",
    "train_data['bathrooms_text'] = train_data['bathrooms_text'].fillna(train_data['bathrooms_text'].mean())\n",
    "\n",
    "# advance drop cols\n",
    "train_data = train_data.drop(['minimum_nights','maximum_nights','minimum_minimum_nights','maximum_minimum_nights',\n",
    "                              'minimum_maximum_nights','maximum_maximum_nights','availability_60','availability_90',\n",
    "                              'number_of_reviews_ltm','number_of_reviews_l30d'], axis=1)\n",
    "\n",
    "# split test and train data\n",
    "test_data = train_data[train_data['price'] == -1].drop(columns=['price'])\n",
    "train_data = train_data[train_data['price'] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c75734-2d55-4456-bba9-3899691a1e11",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d466850-6850-4e9b-9c09-2ee22f870d38",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae863424-1bbd-42d0-a1fb-54704fa44dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5685508456381243\n",
      "1 0.5713357358636781\n",
      "saved... 0\n",
      "2 0.5711416030809643\n",
      "saved... 1\n",
      "3 0.569263008301226\n",
      "4 0.5728253941363052\n",
      "saved... 2\n",
      "5 0.5714007962400428\n",
      "saved... 3\n",
      "6 0.5715305395880754\n",
      "saved... 4\n",
      "7 0.5705588482950533\n",
      "8 0.5713358826321713\n",
      "saved... 5\n",
      "9 0.5741202486845349\n",
      "saved... 6\n",
      "10 0.5723719214260194\n",
      "saved... 7\n",
      "11 0.5723073432889898\n",
      "saved... 8\n",
      "12 0.5720482968984043\n",
      "saved... 9\n",
      "13 0.5723072594212792\n",
      "saved... 10\n",
      "14 0.5718537028432832\n",
      "saved... 11\n",
      "15 0.5723720052937299\n",
      "saved... 12\n",
      "16 0.5737966241569199\n",
      "saved... 13\n",
      "17 0.5694577491248405\n",
      "18 0.573213869371009\n",
      "saved... 14\n",
      "19 0.5731491654324137\n",
      "saved... 15\n",
      "20 0.5704289372115999\n",
      "21 0.573278489441894\n",
      "saved... 16\n",
      "22 0.5732785104088215\n",
      "saved... 17\n",
      "23 0.5710765427045995\n",
      "saved... 18\n",
      "24 0.5721777886433056\n",
      "saved... 19\n",
      "25 0.5732787829788805\n",
      "saved... 20\n",
      "26 0.5728900980749005\n",
      "saved... 21\n",
      "27 0.572307007818148\n",
      "saved... 22\n",
      "28 0.5721127911677237\n",
      "saved... 23\n",
      "29 0.5723722568968611\n",
      "saved... 24\n",
      "30 0.5730193591835981\n",
      "saved... 25\n",
      "31 0.571724525602296\n",
      "saved... 26\n",
      "32 0.5714650598731584\n",
      "saved... 27\n",
      "33 0.573213806470226\n",
      "saved... 28\n",
      "34 0.5727607111646373\n",
      "saved... 29\n",
      "35 0.5739264094388077\n",
      "saved... 30\n",
      "36 0.572113042770855\n",
      "saved... 31\n",
      "37 0.5736028058781202\n",
      "saved... 32\n",
      "38 0.5704290630131655\n",
      "39 0.5734730415631599\n",
      "saved... 33\n",
      "40 0.5721780612133646\n",
      "saved... 34\n",
      "41 0.5728900771079729\n",
      "saved... 35\n",
      "42 0.5728899513064073\n",
      "saved... 36\n",
      "43 0.5723069449173652\n",
      "saved... 37\n",
      "44 0.5718538496117764\n",
      "saved... 38\n",
      "45 0.5693283412476495\n",
      "46 0.5732138064702261\n",
      "saved... 39\n",
      "47 0.5730845872953838\n",
      "saved... 40\n",
      "48 0.5715300154148852\n",
      "saved... 41\n",
      "49 0.5726960910937524\n",
      "saved... 42\n",
      "50 0.5714654163109278\n",
      "saved... 43\n",
      "51 0.5721779354117988\n",
      "saved... 44\n",
      "52 0.5719836977944469\n",
      "saved... 45\n",
      "53 0.5717242949660923\n",
      "saved... 46\n",
      "54 0.5756100956595105\n",
      "saved... 47\n",
      "55 0.571983110720474\n",
      "saved... 48\n",
      "56 0.5728253522024499\n",
      "saved... 49\n",
      "57 0.5730843566591801\n",
      "saved... 50\n",
      "58 0.5726955878874899\n",
      "saved... 51\n",
      "59 0.5726308420150392\n",
      "saved... 52\n",
      "60 0.5718535560747899\n",
      "saved... 53\n",
      "61 0.5739261159018211\n",
      "saved... 54\n",
      "62 0.5740559221506365\n",
      "saved... 55\n",
      "63 0.5736673420812947\n",
      "saved... 56\n",
      "64 0.5695223482287979\n",
      "65 0.5716594232920761\n",
      "saved... 57\n",
      "66 0.5719833413566777\n",
      "saved... 58\n",
      "67 0.5735377455017554\n",
      "saved... 59\n",
      "68 0.5733436546528967\n",
      "saved... 60\n",
      "69 0.5727606482638545\n",
      "saved... 61\n",
      "70 0.5724369608354566\n",
      "saved... 62\n",
      "71 0.5725015599394141\n",
      "saved... 63\n",
      "72 0.5710767943077307\n",
      "saved... 64\n",
      "73 0.5728252683347395\n",
      "saved... 65\n",
      "74 0.572307322322062\n",
      "saved... 66\n",
      "75 0.573214246775706\n",
      "saved... 67\n",
      "76 0.5717890198716153\n",
      "saved... 68\n",
      "77 0.5709473235297572\n",
      "78 0.5732140580733575\n",
      "saved... 69\n",
      "79 0.5725016438071245\n",
      "saved... 70\n",
      "80 0.571724630436934\n",
      "saved... 71\n",
      "81 0.5743146750042353\n",
      "saved... 72\n",
      "82 0.5698460566241235\n",
      "83 0.575868974314675\n",
      "saved... 73\n",
      "84 0.5711411837424121\n",
      "saved... 74\n",
      "85 0.5735378084025381\n",
      "saved... 75\n",
      "86 0.5715301202495232\n",
      "saved... 76\n",
      "87 0.5717242949660923\n",
      "saved... 77\n",
      "88 0.5717892924416741\n",
      "saved... 78\n",
      "89 0.5725015180055588\n",
      "saved... 79\n",
      "90 0.5718538915456316\n",
      "saved... 80\n",
      "91 0.5735379971048866\n",
      "saved... 81\n",
      "92 0.5728902448433939\n",
      "saved... 82\n",
      "93 0.5715301621833785\n",
      "saved... 83\n",
      "94 0.5719184067818786\n",
      "saved... 84\n",
      "95 0.5722425554826838\n",
      "saved... 85\n",
      "96 0.5725659703410229\n",
      "saved... 86\n",
      "97 0.5719834042574605\n",
      "saved... 87\n",
      "98 0.5711417288825299\n",
      "saved... 88\n",
      "99 0.5730196527205846\n",
      "saved... 89\n",
      "100 0.5719832365220396\n",
      "saved... 90\n",
      "101 0.5732138274371538\n",
      "saved... 91\n",
      "102 0.5708824308888133\n",
      "103 0.5726307371804011\n",
      "saved... 92\n",
      "104 0.5714005656038392\n",
      "saved... 93\n",
      "105 0.5729545504103648\n",
      "saved... 94\n",
      "106 0.5713358406983161\n",
      "saved... 95\n",
      "107 0.5723719004590919\n",
      "saved... 96\n",
      "108 0.5728899093725521\n",
      "saved... 97\n",
      "109 0.5719187212857927\n",
      "saved... 98\n",
      "110 0.5701055013863333\n",
      "111 0.5768406446407695\n",
      "saved... 99\n"
     ]
    }
   ],
   "source": [
    "# params to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [500],\n",
    "    'max_depth': [None]\n",
    "}\n",
    "\n",
    "c = 0\n",
    "for seed in np.arange(0, 2000, 1):\n",
    "    set_all_seeds(int(seed))\n",
    "    \n",
    "    # get train data for RF\n",
    "    x_train = train_data.drop(\"price\", axis=1)\n",
    "    y_train = train_data['price'].astype('int64')\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=seed)\n",
    "    grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    grid_search_rf.fit(x_train, y_train)\n",
    "    print(seed, grid_search_rf.best_score_)\n",
    "    if grid_search_rf.best_score_>0.5745:\n",
    "        # get train data for RF\n",
    "        x_train = train_data.drop(\"price\", axis=1)\n",
    "        y_train = train_data['price'].astype('int64')\n",
    "        \n",
    "        # deal with imbalanced data\n",
    "        smote = SMOTE(random_state=seed)\n",
    "        x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "        # print(Counter(y_train))\n",
    "        \n",
    "        rf = RandomForestClassifier(random_state=seed, n_estimators=500, max_depth=None)\n",
    "        rf.fit(x_train, y_train)\n",
    "        \n",
    "        # test\n",
    "        y_pred = rf.predict(test_data)\n",
    "        test_sub = pd.read_csv(\"data/test.csv\")\n",
    "        sub_drop_list = test_sub.columns.tolist()\n",
    "        sub_drop_list.remove('id')\n",
    "        sub_drop_list = pd.Index(sub_drop_list)\n",
    "        test_sub = test_sub.drop(sub_drop_list, axis=1)\n",
    "        test_sub['price'] = pd.DataFrame(y_pred)\n",
    "        test_sub.to_csv('outputs/output_' + str(seed) + '.csv', index=False)\n",
    "        print('saved...', c)\n",
    "        c += 1\n",
    "    if c == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e5ebd1-9c51-4d26-94d1-a52b631fb039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  price  0  1  2  3  4  5\n",
      "0        0     -1  0  0  0  0  0  0\n",
      "1        1     -1  0  0  0  0  0  0\n",
      "2        2     -1  0  0  0  0  0  0\n",
      "3        3     -1  0  0  0  0  0  0\n",
      "4        4     -1  0  0  0  0  0  0\n",
      "...    ...    ... .. .. .. .. .. ..\n",
      "6286  6286     -1  0  0  0  0  0  0\n",
      "6287  6287     -1  0  0  0  0  0  0\n",
      "6288  6288     -1  0  0  0  0  0  0\n",
      "6289  6289     -1  0  0  0  0  0  0\n",
      "6290  6290     -1  0  0  0  0  0  0\n",
      "\n",
      "[6291 rows x 8 columns]\n",
      "        id  price    0  1   2    3   4    5\n",
      "0        0     -1    0  0   2   87  11    0\n",
      "1        1     -1    0  2  78   20   0    0\n",
      "2        2     -1    0  0   0  100   0    0\n",
      "3        3     -1    0  0   0   28  72    0\n",
      "4        4     -1    0  0   3   97   0    0\n",
      "...    ...    ...  ... ..  ..  ...  ..  ...\n",
      "6286  6286     -1    0  0   0    0   0  100\n",
      "6287  6287     -1    0  0   0    0   0  100\n",
      "6288  6288     -1   97  3   0    0   0    0\n",
      "6289  6289     -1  100  0   0    0   0    0\n",
      "6290  6290     -1    0  0  61   39   0    0\n",
      "\n",
      "[6291 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "files = os.listdir('outputs')\n",
    "cnt = pd.read_csv('outputs/'+files[0])\n",
    "cnt['price'] = -1\n",
    "cnt['0'] = 0\n",
    "cnt['1'] = 0\n",
    "cnt['2'] = 0\n",
    "cnt['3'] = 0\n",
    "cnt['4'] = 0\n",
    "cnt['5'] = 0\n",
    "print(cnt)\n",
    "for i in files:\n",
    "    out = pd.read_csv('outputs/'+i)\n",
    "    for j in out.index:\n",
    "        cnt[str(out['price'][j])][j]+=1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee21697-a23c-4b3a-9630-968c0604d4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  price    0  1   2    3   4    5\n",
      "0        0      3    0  0   2   87  11    0\n",
      "1        1      2    0  2  78   20   0    0\n",
      "2        2      3    0  0   0  100   0    0\n",
      "3        3      4    0  0   0   28  72    0\n",
      "4        4      3    0  0   3   97   0    0\n",
      "...    ...    ...  ... ..  ..  ...  ..  ...\n",
      "6286  6286      5    0  0   0    0   0  100\n",
      "6287  6287      5    0  0   0    0   0  100\n",
      "6288  6288      0   97  3   0    0   0    0\n",
      "6289  6289      0  100  0   0    0   0    0\n",
      "6290  6290      2    0  0  61   39   0    0\n",
      "\n",
      "[6291 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "for j in cnt.index:\n",
    "    cnt['price'][j] = np.argmax([cnt['0'][j], cnt['1'][j],cnt['2'][j],cnt['3'][j],cnt['4'][j],cnt['5'][j]])\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7dfd2e3-eb13-4de0-bd28-a6ebf49caa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  price\n",
      "0        0      3\n",
      "1        1      2\n",
      "2        2      3\n",
      "3        3      4\n",
      "4        4      3\n",
      "...    ...    ...\n",
      "6286  6286      5\n",
      "6287  6287      5\n",
      "6288  6288      0\n",
      "6289  6289      0\n",
      "6290  6290      2\n",
      "\n",
      "[6291 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "cnt = cnt.drop('0', axis=1)\n",
    "cnt = cnt.drop('1', axis=1)\n",
    "cnt = cnt.drop('2', axis=1)\n",
    "cnt = cnt.drop('3', axis=1)\n",
    "cnt = cnt.drop('4', axis=1)\n",
    "cnt = cnt.drop('5', axis=1)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d356fd6-5561-4f29-bb90-db943acc579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c4af1-db4d-4c82-9476-0f374d2983a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
