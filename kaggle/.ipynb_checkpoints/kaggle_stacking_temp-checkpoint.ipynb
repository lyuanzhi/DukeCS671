{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d51b54-b66c-4b27-8f52-6ded3de01b29",
   "metadata": {},
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d868e8ca-f1af-4f15-9580-c222aceb087f",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a350f3-b564-4482-83fe-c1f498bcf565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from category_encoders import BinaryEncoder\n",
    "import ast\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, HistGradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.utils import resample\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1851488-ac80-4afb-999f-5e96a8f7e17e",
   "metadata": {},
   "source": [
    "## Set Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d75c673-e59a-4551-a79c-5ddc5cfece6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(RANDOM_SEED):\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed = 1\n",
    "set_all_seeds(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f56404f-f883-4f2b-bb31-02915475343e",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e88ecc4-2712-4ce4-8f84-cf7e7a977055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# comcat train and test data for data process\n",
    "test_data['price'] = -1\n",
    "train_data = pd.concat([train_data, test_data], axis=0)\n",
    "\n",
    "# initial removal of unwanted features\n",
    "drop_columns = ['id','scrape_id','last_scraped','picture_url','host_id','host_name','name']\n",
    "train_data = train_data.drop(drop_columns, axis=1)\n",
    "\n",
    "# avoid err in xgboost\n",
    "train_data['host_verifications'] = train_data['host_verifications'].str.replace('[', '(')\n",
    "train_data['host_verifications'] = train_data['host_verifications'].str.replace(']', ')')\n",
    "\n",
    "# deal with incomplete data\n",
    "categorical_columns_with_nans = ['host_is_superhost', 'bathrooms_text']\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "train_data[categorical_columns_with_nans] = imputer.fit_transform(train_data[categorical_columns_with_nans])\n",
    "\n",
    "beds_imputer = SimpleImputer(strategy='median')\n",
    "train_data['beds'] = beds_imputer.fit_transform(train_data[['beds']])\n",
    "\n",
    "train_data['description'] = train_data['description'].fillna('')\n",
    "\n",
    "# add feature description_length\n",
    "train_data['description_length'] = train_data['description'].apply(len)\n",
    "train_data = train_data.drop('description', axis=1)\n",
    "\n",
    "# # label encode\n",
    "# label_encoder = LabelEncoder()\n",
    "# train_data['host_is_superhost'] = label_encoder.fit_transform(train_data['host_is_superhost'])\n",
    "# train_data['host_has_profile_pic'] = label_encoder.fit_transform(train_data['host_has_profile_pic'])\n",
    "# train_data['host_identity_verified'] = label_encoder.fit_transform(train_data['host_identity_verified'])\n",
    "# train_data['has_availability'] = label_encoder.fit_transform(train_data['has_availability'])\n",
    "# train_data['instant_bookable'] = label_encoder.fit_transform(train_data['instant_bookable'])\n",
    "\n",
    "# onehot encode\n",
    "categorical_columns = train_data.select_dtypes(include=['object']).columns\n",
    "categorical_columns_to_encode = [col for col in categorical_columns if len(train_data[col].unique()) <= 20]\n",
    "train_data = pd.get_dummies(train_data, columns=categorical_columns_to_encode, drop_first=True)\n",
    "\n",
    "# add feature amenities_count\n",
    "train_data['amenities_count'] = train_data['amenities'].apply(lambda x: len(x.split(',')))\n",
    "train_data = train_data.drop('amenities', axis=1)\n",
    "\n",
    "# only keep year info of host_since\n",
    "train_data['host_since'] = pd.to_datetime(train_data['host_since'])\n",
    "train_data['host_since'] = train_data['host_since'].dt.year + train_data['host_since'].dt.month / 12\n",
    "train_data['host_since'] = train_data['host_since'].astype('float64')\n",
    "\n",
    "# extract numbers from bathrooms_text\n",
    "# train_data['bathrooms_shared'] = train_data['bathrooms_text'].isin(['shared', 'Shared'])\n",
    "# train_data['bathrooms_private'] = train_data['bathrooms_text'].isin(['private', 'Private'])\n",
    "train_data['bathrooms_text'] = train_data['bathrooms_text'].replace(to_replace='half', value='0.5', regex=True)\n",
    "train_data['bathrooms_text'] = train_data['bathrooms_text'].replace(to_replace='Half', value='0.5', regex=True)\n",
    "train_data['bathrooms_text'] = train_data['bathrooms_text'].str.extract('(\\d+\\.?\\d*)').astype('float64')\n",
    "train_data['bathrooms_text'] = train_data['bathrooms_text'].fillna(train_data['bathrooms_text'].mean())\n",
    "\n",
    "x = train_data.drop(['price','property_type','neighbourhood_cleansed'], axis=1)\n",
    "scaler = MinMaxScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "gmm = GaussianMixture(n_components=6, covariance_type='full', init_params='kmeans', random_state=seed).fit(x)\n",
    "train_data['gmm_cluster'] = gmm.predict(x)\n",
    "\n",
    "train_data = pd.get_dummies(train_data, columns=['property_type','neighbourhood_cleansed'], drop_first=True)\n",
    "\n",
    "# advance drop cols\n",
    "train_data = train_data.drop(['minimum_nights','maximum_nights','minimum_minimum_nights','maximum_minimum_nights',\n",
    "                              'minimum_maximum_nights','maximum_maximum_nights','availability_60','availability_90',\n",
    "                              'number_of_reviews_ltm','number_of_reviews_l30d'], axis=1)\n",
    "\n",
    "# split test and train data\n",
    "test_data = train_data[train_data['price'] == -1].drop(columns=['price'])\n",
    "train_data = train_data[train_data['price'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae863424-1bbd-42d0-a1fb-54704fa44dbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5774740379220913\n"
     ]
    }
   ],
   "source": [
    "# get train data for RF\n",
    "x_train = train_data.drop(\"price\", axis=1)\n",
    "y_train = train_data['price'].astype('int64')\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=None, n_estimators=500, n_jobs=-1, class_weight='balanced', random_state=seed)\n",
    "pipeline_rf = make_pipeline(SMOTE(random_state=seed), rf)\n",
    "xgboost = XGBClassifier(booster='gbtree', tree_method='auto', n_jobs=-1, \n",
    "                        subsample=0.6, n_estimators=500, learning_rate=0.05, \n",
    "                        min_child_weight=0.4, max_depth=10, gamma=0.5, \n",
    "                        colsample_bylevel=0.8, colsample_bytree=0.6, random_state=seed)\n",
    "\n",
    "estimators = [\n",
    "    ('pipeline_rf', pipeline_rf),\n",
    "    ('xgboost', xgboost)\n",
    "]\n",
    "\n",
    "pipeline_SVC = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('svm', SVC(kernel='linear', random_state=seed))\n",
    "])\n",
    "\n",
    "stack = StackingClassifier(estimators=estimators, final_estimator=pipeline_SVC, n_jobs=-1)\n",
    "stack.fit(x_train, y_train)\n",
    "scores = cross_val_score(stack, x_train, y_train, cv=5, scoring='accuracy')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64252eb6-8707-4881-afac-84d848196b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "y_pred = stack.predict(test_data)\n",
    "test_sub = pd.read_csv(\"data/test.csv\")\n",
    "sub_drop_list = test_sub.columns.tolist()\n",
    "sub_drop_list.remove('id')\n",
    "sub_drop_list = pd.Index(sub_drop_list)\n",
    "test_sub = test_sub.drop(sub_drop_list, axis=1)\n",
    "test_sub['price'] = pd.DataFrame(y_pred)\n",
    "test_sub.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
