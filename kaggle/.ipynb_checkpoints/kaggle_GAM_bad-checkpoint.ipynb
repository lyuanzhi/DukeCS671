{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d51b54-b66c-4b27-8f52-6ded3de01b29",
   "metadata": {},
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d868e8ca-f1af-4f15-9580-c222aceb087f",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a350f3-b564-4482-83fe-c1f498bcf565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from category_encoders import BinaryEncoder\n",
    "import ast\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.utils import resample\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pygam import LogisticGAM, s, l, f, te\n",
    "from pygam.terms import TermList\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1851488-ac80-4afb-999f-5e96a8f7e17e",
   "metadata": {},
   "source": [
    "## Set Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d75c673-e59a-4551-a79c-5ddc5cfece6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "def set_all_seeds(RANDOM_SEED):\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_all_seeds(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f56404f-f883-4f2b-bb31-02915475343e",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e88ecc4-2712-4ce4-8f84-cf7e7a977055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# comcat train and test data for data process\n",
    "test_data['price'] = -1\n",
    "train_data = pd.concat([train_data, test_data], axis=0)\n",
    "\n",
    "# initial removal of unwanted features\n",
    "drop_columns = ['id','scrape_id','last_scraped','picture_url','host_id','host_name','name']\n",
    "train_data = train_data.drop(drop_columns, axis=1)\n",
    "\n",
    "# deal with incomplete data\n",
    "categorical_columns_with_nans = ['host_is_superhost', 'bathrooms_text']\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "train_data[categorical_columns_with_nans] = imputer.fit_transform(train_data[categorical_columns_with_nans])\n",
    "\n",
    "beds_imputer = SimpleImputer(strategy='median')\n",
    "train_data['beds'] = beds_imputer.fit_transform(train_data[['beds']])\n",
    "\n",
    "train_data['description'] = train_data['description'].fillna('')\n",
    "\n",
    "# add feature description_length\n",
    "train_data['description_length'] = train_data['description'].apply(len)\n",
    "train_data = train_data.drop('description', axis=1)\n",
    "\n",
    "# add feature amenities_count\n",
    "train_data['amenities_count'] = train_data['amenities'].apply(lambda x: len(x.split(',')))\n",
    "train_data = train_data.drop('amenities', axis=1)\n",
    "\n",
    "# only keep year info of host_since\n",
    "train_data['host_since'] = pd.to_datetime(train_data['host_since'])\n",
    "train_data['host_since'] = train_data['host_since'].dt.year + train_data['host_since'].dt.month / 12\n",
    "train_data['host_since'] = train_data['host_since'].astype('float64')\n",
    "\n",
    "# # extract numbers from bathrooms_text\n",
    "train_data['bathrooms_text'] = train_data['bathrooms_text'].str.extract('(\\d+\\.?\\d*)').astype('float64')\n",
    "train_data['bathrooms_text'] = train_data['bathrooms_text'].fillna(train_data['bathrooms_text'].mean())\n",
    "\n",
    "# label encode\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_columns = train_data.select_dtypes(include=['object']).columns\n",
    "for i in categorical_columns:\n",
    "    train_data[i] = label_encoder.fit_transform(train_data[i])\n",
    "\n",
    "train_data = train_data.drop(['property_type'], axis=1)\n",
    "\n",
    "# split test and train data\n",
    "test_data = train_data[train_data['price'] == -1].drop(columns=['price'])\n",
    "train_data = train_data[train_data['price'] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ace214-2125-4536-91bc-8c58559bd92f",
   "metadata": {},
   "source": [
    "## GAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8ef3fda-bfbc-4fd9-b9e5-e7f0ff2a20e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pygam\\links.py:151: RuntimeWarning: divide by zero encountered in divide\n",
      "  return dist.levels / (mu * (dist.levels - mu))\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pygam\\pygam.py:629: RuntimeWarning: overflow encountered in square\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pygam\\pygam.py:629: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pygam\\links.py:151: RuntimeWarning: divide by zero encountered in divide\n",
      "  return dist.levels / (mu * (dist.levels - mu))\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pygam\\pygam.py:629: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pygam\\pygam.py:629: RuntimeWarning: overflow encountered in square\n",
      "  self.link.gradient(mu, self.distribution) ** 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5296289100446863\n"
     ]
    }
   ],
   "source": [
    "# get train data for GAM\n",
    "X_train = train_data.drop(\"price\", axis=1)\n",
    "y_train = train_data['price'].astype('int64')\n",
    "X_test = test_data\n",
    "\n",
    "# Since PyGAM does not handle multiclass classification out of the box, we need to binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "y_train_binarized = lb.fit_transform(y_train)\n",
    "\n",
    "# We have to fit a separate model for each class\n",
    "gam_models = []\n",
    "for i in range(y_train_binarized.shape[1]):\n",
    "    terms = []\n",
    "    for index in range(len(X_train.columns)):\n",
    "        if X_train.dtypes[index] == 'float64':\n",
    "            terms.append(s(index))\n",
    "        if X_train.dtypes[index] == 'int32':\n",
    "            terms.append(l(index))\n",
    "        if X_train.dtypes[index] == 'int64':\n",
    "            terms.append(s(index))\n",
    "    if terms:\n",
    "        terms = TermList(*terms)\n",
    "    gam = LogisticGAM(terms=terms)\n",
    "    gam.fit(X_train, y_train_binarized[:, i])\n",
    "    gam_models.append(gam)\n",
    "\n",
    "# Now we predict the probability of each class for the test set\n",
    "y_pred_probabilities = []\n",
    "for model in gam_models:\n",
    "    y_pred_probabilities.append(model.predict_proba(X_train))\n",
    "\n",
    "# Transpose to get the class probabilities in the correct shape\n",
    "y_pred_probabilities = np.array(y_pred_probabilities).T\n",
    "\n",
    "# Select the class with the highest probability\n",
    "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c99001-6b54-4ad1-a989-1a707f2d7504",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probabilities = []\n",
    "for model in gam_models:\n",
    "    y_pred_probabilities.append(model.predict_proba(X_test))\n",
    "\n",
    "# Transpose to get the class probabilities in the correct shape\n",
    "y_pred_probabilities = np.array(y_pred_probabilities).T\n",
    "\n",
    "# Select the class with the highest probability\n",
    "y_pred = np.argmax(y_pred_probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e05ec20-5989-4295-bf35-b5740f993b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_sub = pd.read_csv(\"data/test.csv\")\n",
    "sub_drop_list = test_sub.columns.tolist()\n",
    "sub_drop_list.remove('id')\n",
    "sub_drop_list = pd.Index(sub_drop_list)\n",
    "test_sub = test_sub.drop(sub_drop_list, axis=1)\n",
    "test_sub['price'] = pd.DataFrame(y_pred)\n",
    "test_sub.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
