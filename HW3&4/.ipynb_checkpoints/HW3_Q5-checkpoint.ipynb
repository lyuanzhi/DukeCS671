{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51aa32f5-dc1f-4ed2-ab49-aca39b79b7c6",
   "metadata": {},
   "source": [
    "# Q5 Boosting Algorithm Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a44e39-afb3-48b2-88ff-dc8a22d41dfa",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679fa44b-d70a-4701-bf6d-8c1d6347813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read data from csv file\n",
    "data = pd.read_csv(\"Titanic.csv\")\n",
    "data = data.dropna(axis='columns')\n",
    "data.loc[data['Sex'] == 'female', 'Sex'] = 1\n",
    "data.loc[data['Sex'] == 'male', 'Sex'] = 0\n",
    "data['Sex'] = pd.to_numeric(data['Sex'])\n",
    "\n",
    "# split train and test dataset\n",
    "x = data.drop(\"Survived\", axis=1)\n",
    "y = data['Survived']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, train_size=0.8, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eb16de-5923-41c6-a9bf-8bc6a0f23a52",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de1a5372-1444-41de-a7be-67e79de40581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn's Adaboost\n",
    "# tune parameters of the Adaboost using cv\n",
    "adaboost_hyperparam = {\n",
    "    'base_estimator': [DecisionTreeClassifier(max_depth=2), DecisionTreeClassifier(max_depth=3)],\n",
    "    'n_estimators': [50, 75, 100],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1],\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}\n",
    "adaboost_model = AdaBoostClassifier()\n",
    "adaboost_grid = GridSearchCV(adaboost_model, adaboost_hyperparam, cv=5, scoring='accuracy')\n",
    "adaboost_grid.fit(x_train, y_train)\n",
    "\n",
    "best_adaboost_model = adaboost_grid.best_estimator_\n",
    "# print(adaboost_grid.best_score_)\n",
    "# print(adaboost_grid.best_params_)\n",
    "# print(best_adaboost_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875118db-54a4-4015-b780-1895779db1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "# tune parameters of the XGBoost using cv\n",
    "xgboost_hyperparam = {\n",
    "    'booster': ['gbtree'],\n",
    "    'tree_method': ['auto', 'exact', 'approx'],\n",
    "    'n_estimators': [30, 50, 75, 100],\n",
    "    'eta': [0.01, 0.1, 0.5, 1],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "xgboost_model = XGBClassifier()\n",
    "xgboost_grid = GridSearchCV(xgboost_model, xgboost_hyperparam, cv=5, scoring='accuracy')\n",
    "xgboost_grid.fit(x_train, y_train)\n",
    "\n",
    "best_xgboost_model = xgboost_grid.best_estimator_\n",
    "# print(xgboost_grid.best_score_)\n",
    "# print(xgboost_grid.best_params_)\n",
    "# print(best_xgboost_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7618bb24-ba1d-4bee-b306-597d2b62f9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                f1   roc_auc  accuracy\n",
      "Adaboost  0.671642  0.735178  0.754190\n",
      "XGBoost   0.715328  0.768709  0.782123\n"
     ]
    }
   ],
   "source": [
    "# performance on the test set\n",
    "y_pred_ada = best_adaboost_model.predict(x_test)\n",
    "y_pred_xgb = best_xgboost_model.predict(x_test)\n",
    "\n",
    "table_data = [\n",
    "    [f1_score(y_test, y_pred_ada), roc_auc_score(y_test, y_pred_ada), accuracy_score(y_test, y_pred_ada)],\n",
    "    [f1_score(y_test, y_pred_xgb), roc_auc_score(y_test, y_pred_xgb), accuracy_score(y_test, y_pred_xgb)]\n",
    "]\n",
    "table = pd.DataFrame(table_data, index=['Adaboost', 'XGBoost'], columns=['f1', 'roc_auc', 'accuracy'])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07a0c82-3111-41a4-abad-777816ea7683",
   "metadata": {},
   "source": [
    "### Comment on performance difference\n",
    "When random_state of train_test_split is 42, XGBoost outperforms Adaboost in f1 score, auc, and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703fd1e-5fea-4d2b-ba57-ca2e4dfc76d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
