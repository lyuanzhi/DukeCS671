{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vV8Z-_edZoAo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary dependencies\n",
    "import argparse\n",
    "import os, sys\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def set_all_seeds(RANDOM_SEED):\n",
    "    random.seed(RANDOM_SEED)     # python random generator\n",
    "    np.random.seed(RANDOM_SEED)  # numpy random generator\n",
    "\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_all_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BwOSbMuZZoAp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleCIFAR10Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCIFAR10Classifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 5)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3)\n",
    "        self.fc1   = nn.Linear(16*6*6, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# useful libraries\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "##################\n",
    "# YOUR CODE HERE #\n",
    "##################\n",
    "\n",
    "# adjust batch size to your need\n",
    "batch_size = \n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "val_size = int(0.5 * len(testset))\n",
    "test_size = len(testset) - val_size\n",
    "valset, testset = torch.utils.data.random_split(testset, [val_size, test_size])\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "print(len(trainset), len(valset), len(testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJ4YB7QvV098",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "iivPVzUvZoAu",
    "outputId": "c8fe0d49-0b93-41aa-b456-ae03ab910a5e",
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "net = SimpleCIFAR10Classifier().cuda()\n",
    "INITIAL_LR = 0.01\n",
    "MOMENTUM = 0.9\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=INITIAL_LR, momentum=MOMENTUM)\n",
    "\n",
    "EPOCHS = 30\n",
    "CHECKPOINT_FOLDER = \"./saved_model\"\n",
    "best_val_acc = 0\n",
    "\n",
    "# Training Loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for i in range(0, EPOCHS):\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    print(\"Epoch %d:\" %i)\n",
    "\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "\n",
    "    # Record training loss\n",
    "    train_loss = 0 \n",
    "\n",
    "    # Looping through training loader\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        ##################\n",
    "        # YOUR CODE HERE #\n",
    "        ##################\n",
    "\n",
    "        # Send input and target to device\n",
    "\n",
    "        # compute the model output logits and training loss\n",
    "        \n",
    "        # back propogation & optimizer update parametes\n",
    "\n",
    "        # calculate predictions\n",
    "        predictions = \n",
    "        correct_examples += \n",
    "        total_examples += inputs.shape[0]\n",
    "\n",
    "    # calculate average training loss and accuracy\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    \n",
    "    # Evaluate the validation set performance\n",
    "    net.eval()\n",
    "\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "\n",
    "    # Record validation loss\n",
    "    val_loss = 0\n",
    "\n",
    "    # disable gradient during validation, which can save GPU memory\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            ##################\n",
    "            # YOUR CODE HERE #\n",
    "            ##################\n",
    "            \n",
    "            # Send input and target to device\n",
    "\n",
    "            # compute the model output logits and training loss\n",
    "\n",
    "            # count the number of correctly predicted samples in the current batch\n",
    "\n",
    "    # calculate average validation loss and accuracy\n",
    "    avg_loss = val_loss / len(val_loader)\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
    "    val_losses.append(avg_loss)\n",
    "    \n",
    "    # save the model checkpoint\n",
    "    if avg_acc > best_val_acc:\n",
    "        best_val_acc = avg_acc\n",
    "\n",
    "        if not os.path.exists(CHECKPOINT_FOLDER):\n",
    "           os.makedirs(CHECKPOINT_FOLDER)\n",
    "        print(\"Saving ...\")\n",
    "        state = {'state_dict': net.state_dict(),\n",
    "                'epoch': i,\n",
    "                'lr': current_learning_rate}\n",
    "        torch.save(state, os.path.join(CHECKPOINT_FOLDER, 'best_model.bin'))\n",
    "\n",
    "    print('')\n",
    "\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# YOUR CODE HERE #\n",
    "##################\n",
    "\n",
    "# load trained model weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# YOUR CODE HERE #\n",
    "##################\n",
    "\n",
    "# write another loop to evaluate trained model performance on the test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# YOUR CODE HERE #\n",
    "##################\n",
    "\n",
    "# visualize model loss curves (both train and loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# (C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "INITIAL_LR = 0.01\n",
    "net = SimpleCIFAR10Classifier().cuda()\n",
    "MOMENTUM = 0.9\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=INITIAL_LR, momentum=MOMENTUM)\n",
    "\n",
    "EPOCHS = 30\n",
    "CHECKPOINT_FOLDER = \"./saved_model\"\n",
    "\n",
    "##################\n",
    "# YOUR CODE HERE #\n",
    "##################\n",
    "\n",
    "# set your own L1 regularization weight \n",
    "REG = \n",
    "\n",
    "# write training loops with L1 regularization and validation loops (Hint: similar to (a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# YOUR CODE HERE #\n",
    "##################\n",
    "\n",
    "# load trained model weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# YOUR CODE HERE #\n",
    "##################\n",
    "\n",
    "# write another loop to evaluate trained model performance on the test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# YOUR CODE HERE #\n",
    "##################\n",
    "\n",
    "# visualize model loss curves (both train and loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualize the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for name, module in net.named_modules():\n",
    "    if 'conv' in name or 'fc' in name:\n",
    "        ##################\n",
    "        # YOUR CODE HERE #\n",
    "        ##################\n",
    "      \n",
    "        # extract weight from layers\n",
    "        \n",
    "    \n",
    "        # Visualize the weights\n",
    "        _ = plt.hist(weight, bins=20)\n",
    "        plt.title(\"Weight histogram of layer \"+name)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "INITIAL_LR = 0.01\n",
    "net = SimpleCIFAR10Classifier().cuda()\n",
    "MOMENTUM = 0.9\n",
    "REG = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "EPOCHS = 30\n",
    "CHECKPOINT_FOLDER = \"./saved_model\"\n",
    "\n",
    "##################\n",
    "# YOUR CODE HERE #\n",
    "##################\n",
    "\n",
    "# set your own L2 regularization weight \n",
    "REG = \n",
    "optimizer = optim.SGD(net.parameters(), lr=INITIAL_LR, momentum=MOMENTUM, weight_decay=REG)\n",
    "\n",
    "# write training loops with L2 regularization and validation loops (Hint: similar to (a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# YOUR CODE HERE #\n",
    "##################\n",
    "\n",
    "# load trained model weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# YOUR CODE HERE #\n",
    "##################\n",
    "\n",
    "# write another loop to evaluate trained model performance on the test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##################\n",
    "# YOUR CODE HERE #\n",
    "##################\n",
    "\n",
    "# visualize model loss curves (both train and loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualize the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for name, module in net.named_modules():\n",
    "    if 'conv' in name or 'fc' in name:\n",
    "        ##################\n",
    "        # YOUR CODE HERE #\n",
    "        ##################\n",
    "      \n",
    "        # extract weight from layers\n",
    "        \n",
    "    \n",
    "        # Visualize the weights\n",
    "        _ = plt.hist(weight, bins=20)\n",
    "        plt.title(\"Weight histogram of layer \"+name)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# comment on the differences between L1 and L2 regularization. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "b11t8AObPAG_",
    "Zk2ykaHlSgZ5",
    "1Pz5T6QRWQ92"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}